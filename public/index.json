[{"content":"AML random notes Introduction to Machine Learning Week  Loss functions    L1 vs L2\nL1 better for outliers, but L2 easier to solve. L1 is useful when data is corrupt with outliers. Consider L1 vs L2 as mean vs median (think about their minimas). L1 has constant gradient.\nCons : Cases where both give undesirable predictions.\n  Huber loss Linear above delta, quadratic below it. $\\delta$ is critical hyperparameter. (Need to train it) Better than L1 and L2 as best of both worlds. Has variants for smoothening the curve.\n  Log-Cosh Loss Smoother than L2. It has all the advantages of Huber loss, and it‚Äôs twice differentiable everywhere. Why 2nd derivative? Great that you asked. It\u0026rsquo;s when using Newton‚Äôs method to find the optimum as in XGBoost. Cons : Log-cosh loss isn‚Äôt perfect. It still suffers from the problem of gradient and hessian for very large off-target predictions being constant, therefore resulting in the absence of splits for XGBoost. Takeaway - ‚ö†Ô∏è TODO\n  Quantile Loss The Elephant in the room ‚ö†Ô∏è TODO\n  Focal Loss ‚ö†Ô∏è TODO\n   Gradient Descent\nOptimization problem : $$\\mathcal L(w) \\rightarrow {\\underset {\\ w} min}\\ .$$\n Stopping criterion :   $\\lVert w^t - w^{t-1}\\rVert \u0026lt; \\epsilon\\quad$ where $w^t = w^{t-1} - \\eta_t\\nabla L(w^{t-1})\\ and \\ \\epsilon.$    ","permalink":"http://example.org/posts/ml/","summary":"AML random notes Introduction to Machine Learning Week  Loss functions    L1 vs L2\nL1 better for outliers, but L2 easier to solve. L1 is useful when data is corrupt with outliers. Consider L1 vs L2 as mean vs median (think about their minimas). L1 has constant gradient.\nCons : Cases where both give undesirable predictions.\n  Huber loss Linear above delta, quadratic below it. $\\delta$ is critical hyperparameter.","title":"Ml"},{"content":"A First Course In Probability tags: Mathematics Probability Chapter 1, 2, 3 - Basic stuff üìù Theoretical Takeaways  Considering question 80, if a particular formulation gets stuck again, try to backtrack if the paradigm seems correct. Try to find different approaches for finding the same answer üòâ. Considering the Conditional Probability, keep in mind to first cascade the conditional probability i.e. consider every sub-event to create sub-linear dependencies. Go on proving afterwards whether the events are independent or not. Gamblers Ruin Consider $A$ and $B$ plays a game where they exchange 1 unit money, if they initially have a and b units respectively. This is purely analogous to a RANDOM WALK. Consider a line segment $[0, N]$, then the case when $A$ wins is analogous to the the walk ending in N and similarly for $B$. üò≤ Does the game end? Adding the probabilities, we get answer as 1. Indicator Variables Random variables which have value $!$ for success of an event, and $0$ otherwise. Note that $E[I] = P(A)\\ .$ Compositions of these Indicator Variables for each of the iteration is $X$, the random variable for such a distribution.  Chapter 4 - Random Variables and their basic postulates üìù Theoretical Takeaways  Go with the intuition. Think clearly about the formula (esp. regarding the Expectancy of the Random Variables), and try to formulate your intuition better. Suppose that you can\u0026rsquo;t formalise an equality, try to think of other formulations. For example, try to prove the formulation for an inequality, and then use it to derive the result üò≤. Refer to pg. 148 for the fact that mathematical rigor should always be maintained and it should not hinder your ability to think further. Thinking of the same problem with one formualtion might be tough, but considering a not so dissimilar formulation might really work out.  üìù Formal Theory   For a random variable ${X}$, the function ${F}$ defined as $$ F(x) = P\\{X \\leqslant x\\} \\qquad \\forall \\ \\ x \\in \\left( -\\infty, \\infty \\right) $$ is called the Cumulative Distribution Function, as the function suggests.\n  Probability Mass function for a discrete random variable is discrete üòõ.\n  Let $X$ be a random variable having a probability mass function ${p(x)}$. The expectation or the expected value of the random variable ${X}$ is defined as $$E[X] = \\sum_{x:p(x) \\gt 0} xp(x)$$ Looking closely, it corresponds to the _weighted average_ of the values which the random variable takes. If you are a physicist, think of it as the experiment for finding the _centre of mass_ of the object.\n  üóíÔ∏è Important: $E[X^2] \\ne {E}^2\\ .$\n  Proposition: If $X$ is a random variable taking value ${a_i}$ with probability ${p(a_i)}$, then for any real-valued function ${g}$, $$E[g] = \\sum_i{g(x_i)p(x_i)} $$\n  Expectancy is a linear function, i.e. $$ E[aX + b]=aE+b $$\n  The quantity defined as $$E[X^n]=\\sum_{x:p(x)\u0026gt;0} x^np(x)$$ is called the **nth moment of X**. This also means that **mean** of $X$ is the **first moment of X**.\n  If $X$ is a random variable with mean $\\mu$, then the variance of $X$ is defined by $$Var=E[(X-\\mu^2)] = E[X^2]-E^2\\ . $$\n  üóíÔ∏è $Var$ is not a linear function. Rather, it varies as $$Var[aX+b]=a^2Var\\ .$$\n  Bernoulli and Binomial Random Variables The Bernoulli random variable exists for a binary situation (win/loss). Let the probability of an event be $p$ and that of its complimentary event be $1-p$. Then, the probability mass function of a binomial random variable is given as $$p(i)={n \\choose i}p^i(1-p)^{n-i}\\ .$$\n  Property: $$E[X^k]=npE[(Y + 1)^{k - 1}]$$ where $Y$ is a random variable with the parameters $(n-1, p)$ .\n Corollary : $$E=np$$ $$Var=np(1-p)$$    Proposition : If $X$ is a binomial random variable with parameters $(n, p)$, where ${0 \u0026lt; p \u0026lt; 1}$, then as $k$ goes from $0$ to $n$, $P{X = k}$ first increases monotonically and then decreases monotonically, reaching its largest value when $k$ is the largest integer less than or equal to $(n + 1)p$, i.e. $$k=\\sup{k \\in \\Bbb W : k \\le (n+1)p}\\ .$$\n  Poisson Random Variable A random variable $X$ taking values $i \\in \\Bbb W$ is Poisson Random Variable with the parameter $\\lambda$, for some $\\lambda \u0026gt; 0$, such that $$p(i)=P[X=i]=e^{-\\lambda}{\\frac{\\lambda^i}{i!}}\\ .$$ If there are $n$ independent binomial trials, when $n$ is large and $p$ is sufficiently small, the number of successes occuring is approximately $\\lambda=np$.\n Property : The $Variance$ aned $Expected\\ Value$ of a Poisson Random Variable both equal to $\\lambda$. Poisson\u0026rsquo;s paradigm is also applicable in scenarios of weak independence( Refer to Random Doubts).  $\\mathbf {Poisson\u0026rsquo;s\\ Paradigm}$ : Consider $n$ events, with $p_i$ probability that event $i$ occurs, $\\forall\\ i = 1, \\dots, n .$ If the $p_i$ are sufficiently small, and the trials are independent or at most weakly dependent, then the number of these events that occur have a Poisson distribution with mean $\\sum_{i=1}^np_i$. If having difficulty in realising this distribution, just consider this as a continuous function having known discrete values, which have already benn studied. For choosing a $\\lambda$ for Poisson distribution, consider it as mean of probabilities for the event occuring as such.\n‚ö†Ô∏è Maintain rigor for as to each and every step of the proof of reasoning.\nUsing Poisson\u0026rsquo;s paradigm\n First check what the question demands for (the variables, the constants and all).\n  Chapter 5 Independent Random Variables $$P{X \\in A, Y \\in B} = P{X \\in A}P{Y \\in B}$$ for sets of real numbers $A$ and $B$, i.e. Events $E_a = {X \\in A}$ and resp. should be independent. Given equation is equivalent to $$P{X \\le a, Y \\le b} = P{X \\le a}P{Y \\le b}$$ for all $a, b$. Also, independence $\\implies F(a, b) = F_x(a)F_y(b)\\qquad \\forall\\ a, b.$ For discrete, change accordingly. For jointly continuous case, $f(x, y) = f(x)f(y)\\qquad \\forall\\ x, y.$\nCovariance and Correlation\nMoment Generating Functions\nPoisson Process MIT\nPoisson Process CMU (Formal)\nPoisson Process CMU (More Formal)\nMCMC\nMonte-Carlo State space\n[\n","permalink":"http://example.org/posts/pnc/","summary":"A First Course In Probability tags: Mathematics Probability Chapter 1, 2, 3 - Basic stuff üìù Theoretical Takeaways  Considering question 80, if a particular formulation gets stuck again, try to backtrack if the paradigm seems correct. Try to find different approaches for finding the same answer üòâ. Considering the Conditional Probability, keep in mind to first cascade the conditional probability i.e. consider every sub-event to create sub-linear dependencies. Go on proving afterwards whether the events are independent or not.","title":"Pnc"},{"content":"","permalink":"http://example.org/section/","summary":"section","title":"Section"}]